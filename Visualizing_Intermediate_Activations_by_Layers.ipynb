{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Visualizing Intermediate Activations by Layers.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_t8odd5sfXQ",
        "colab_type": "text"
      },
      "source": [
        "# Visualizing intermediate activation in Convolutional Neural Networks with Keras\n",
        "\n",
        "* Medium post it's based on: https://towardsdatascience.com/visualizing-intermediate-activation-in-convolutional-neural-networks-with-keras-260b36d60d0 \n",
        "* GitHub version with full code: https://github.com/gabrielpierobon/cnnshapes/blob/master/README.md\n",
        "\n",
        "\n",
        "> \"In order to extract the feature maps we want to look at, we’ll create a Keras model that takes batches of images as input, and outputs the activations of all convolution and pooling layers. To do this, we’ll use the Keras class Model. A model is instantiated using two arguments: an input tensor (or list of input tensors) and an output tensor (or list of output tensors). The resulting class is a Keras model, just like the Sequential models, mapping the specified inputs to the specified outputs. What sets the Model class apart is that it allows for models with multiple outputs, unlike Sequential.\"\n",
        "\n",
        "## Code for printing all layers \n",
        "\n",
        "Once you have trained a CNN model, change the model name in the code below and run the code. It should print out the images from each layer.\n",
        "\n",
        "Note that I'm having a little trouble with showing all the images. It so far only shows multiples of `images_per_row` which I've set to 6. So it shows all 6 images in the first two layers of LeNet5 and the first 12 images of the next two layers that actually have 16 images each.\n",
        "\n",
        "I'll fix it to it runs on VGG--it currently runs out of memory. \n",
        "\n",
        "Scroll down for code that shows the images of a single layer that you choose. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bToFoJNg6LQZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Code Modified from: https://towardsdatascience.com/visualizing-intermediate-activation-in-convolutional-neural-networks-with-keras-260b36d60d0\n",
        "\n",
        "# Model to feed in\n",
        "model = LeNet5_model2\n",
        "\n",
        "# Index of the sample image \n",
        "imgnum=3\n",
        "\n",
        "# Print out all the layers, their names, and shapes \n",
        "print(model.summary())\n",
        "\n",
        "# These are the layer outputs \n",
        "layer_outputs = [layer.output for layer in model.layers]\n",
        "\n",
        "activation_model = models.Model(inputs=model.input, outputs=layer_outputs)\n",
        "\n",
        "# This is where you predict an input. I'm gonna try predicting just one image later, instead of the whole dev set, since VGG 16 is running out of memory \n",
        "activations = activation_model.predict(X_dev) \n",
        "# Each element in activations is a separate layer. Refer to summary for what these look like. \n",
        "# You could also do something like: activation[0].shape for the shape of the first layer \n",
        "# The shape will be in this form:   number of examples X size of feature map x size of feature map x number of channels\n",
        "\n",
        "layer_names = []\n",
        "for layer in model.layers:\n",
        "    layer_names.append(layer.name) # Names of the layers, so you can have them as part of your plot\n",
        "    \n",
        "images_per_row = 6    \n",
        "\n",
        "for layer_name, layer_activation in zip(layer_names, activations): # Displays the feature maps\n",
        "    ## Only if shape has 4 numbers. So ignore flattened/fully connected layers\n",
        "    if len(layer_activation.shape) == 4:\n",
        "      \n",
        "      n_features = layer_activation.shape[-1] # Number of features in the feature map\n",
        "      size = layer_activation.shape[1] #The feature map has shape (1, size, size, n_features).\n",
        "\n",
        "      \n",
        "      n_cols =  n_features // images_per_row # Tiles the activation channels in this matrix\n",
        "      display_grid = np.zeros((size * n_cols, images_per_row * size))\n",
        "\n",
        "      for col in range(n_cols): # Tiles each filter into a big horizontal grid\n",
        "          for row in range(images_per_row):\n",
        "              channel_image = layer_activation[imgnum,   # image number\n",
        "                                                :, :,\n",
        "                                                col * images_per_row + row]\n",
        "              # Post-processes the feature to make it visually palatable\n",
        "              channel_image -= channel_image.mean() \n",
        "              channel_image /= channel_image.std()\n",
        "              channel_image *= 64\n",
        "              channel_image += 128\n",
        "              channel_image = np.clip(channel_image, 0, 255).astype('uint8')\n",
        "              display_grid[col * size : (col + 1) * size, # Displays the grid\n",
        "                            row * size : (row + 1) * size] = channel_image\n",
        "      scale = 1. / size\n",
        "      plt.figure(figsize=(scale * max(display_grid.shape[1], 1),\n",
        "                          scale * max(display_grid.shape[0], 1)))\n",
        "      plt.title(layer_name)\n",
        "      plt.grid(False)\n",
        "      plt.imshow(display_grid, aspect='auto', cmap=\"gray\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MCrqra-m3I8Y",
        "colab_type": "text"
      },
      "source": [
        "## Printing a single channel in a single layer\n",
        "\n",
        "The code above is for looping through all channels in all layers. The code below is to visualize select channels in a single layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4TsahzVis-Fg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# I want to see every layer, actually.\n",
        "# Let's stick to image indexed 0\n",
        "\n",
        "def show_img_n_1stlayer(img_index, channel_index, layer_activation):\n",
        "  fig, axis = plt.subplots(1, 2)\n",
        "  fig.suptitle(\"Layer index:\" + str(channel_index))\n",
        "  \n",
        "  # First image is the original face\n",
        "  axis[0].imshow(X_dev[img_index][:, :, 0],cmap=\"gray\")\n",
        "  axis[0].axis(\"off\")\n",
        "\n",
        "  # Second image is the nth filter of the first layer \n",
        "  axis[1].imshow(layer_activation[img_index, :, :, channel_index],cmap=\"gray\")\n",
        "  axis[1].axis(\"off\")\n",
        "\n",
        "  fig.show()\n",
        "\n",
        "\n",
        "# Choose layer here\n",
        "layer_index = 1\n",
        "# Choose channel here\n",
        "channel_num = 0\n",
        "# sample image\n",
        "imgnum=3\n",
        "\n",
        "\n",
        "show_img_n_1stlayer(img_index = imgnum, \n",
        "                    channel_index=channel_num, \n",
        "                    layer_activation=activations[layer_index])"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}